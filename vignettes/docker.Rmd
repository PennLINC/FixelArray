---
title: "Using Docker image"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Using Docker image}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

Besides running `ModelArray` and `ConFixel` on a local computer, users also have an option to run it on High Performance Computing (HPC) clusters. When using HPC clusters, users may not have full privilege to install all the dependent packages. Therefore, we also provide a Docker image of `ModelArray + ConFixel` to enhance portability and to facilitate running on clusters.

The Docker image is publicly available at [Docker Hub](https://hub.docker.com/r/pennlinc/modelarray_confixel).

Here we cover how to use this Docker image to run `ModelArray` and `ConFixel`. If you're new to `ModelArray`, we suggest starting with webpage `vignette("walkthrough")` which has more detailed explanations.

Before going through this documentation, please download demo fixel-wise data we provide from OSF into a directory e.g., `/myProject/data` - please refer to Step 1.1 and Step 1.2 in webpage `vignette("walkthrough")`. The data we provide includes subject-level fixel-wise FDC data (.mif files) and a .csv file of cohort phenotypes:

``` {.console}
/myProject
├── code    # we'll explain this folder later
└── data
    ├── cohort_FDC_n100.csv
    └── FDC
        ├── directions.mif
        ├── index.mif
        ├── sub-010b693.mif
        ├── sub-0133f31.mif
        ├── sub-063fd82.mif
        ├── ...

```

## Using singularity to run on HPC clusters
Prerequisite: Singularity installed HCP clusters. If not, please contact the HPC's administrator.

Although HPC clusters usually only support Singularity but not Docker, it is still fine to use the Docker image.

### Step 1. Pull the container from Docker Hub
We first pull the container from Docker Hub using `singularity pull`:

```{.console}
cd /Software     # let's put the image in folder `/Software`
singularity pull docker://pennlinc/modelarray_confixel:latest
```
You may replace the `latest` to any tagged version, e.g., `0.1.2`. You should see a .sif image in current directory: `modelarray_confixel_latest.sif`

After pulling, let's make sure it's success:
```{.console}
singularity run --cleanenv \
    modelarray_confixel_latest.sif \
    R
```

You should have entered an R environment. You should be able to load `ModelArray` R package as you usually do in RStudio: `library(ModelArray)`. Now let's start with the data conversion.

### Step 2. Convert data into an HDF5 file using ConFixel
The `ConFixel` and dependent packages are also included in this container. Let's run the singularity image to convert the list of .mif files into an HDF5 file that `ModelArray` requires:
<!---
Note: tested and found that `dir_data` begins with `~` (e.g.,  `dir_data="~/myProject/data"`) did not work....`cd $dir_data` throws error.
--->

```{.console}
dir_singularity="/Software"    # where the .sif file is
fn_singularity="${dir_singularity}/modelarray_confixel_latest.sif"   # filename of singularity image with full path

dir_data="/myProject/data"   # where the data is downloaded and unzipped
dir_mounted_data="/mnt/data"   # the mounted directory within singularity image

cd $dir_data
singularity run --cleanenv -B ${dir_data}:${dir_mounted_data} \
    ${fn_singularity} \
    confixel \
    --index-file FDC/index.mif \
    --directions-file FDC/directions.mif \
    --cohort-file cohort_FDC_n100.csv \
    --relative-root ${dir_mounted_data} \
    --output-hdf5 demo_FDC_n100.h5


```

As you probably noted, we need to "mount" directories that are on the cluster but outside the singularity container, into directories within the container. This is done by `-B` when using `singularity run`.

If, for your case, any input file or output file is (or will be) in another directory, please make sure that directory is mounted too, by providing a comma-separated mounting list, e.g., `-B /path/to/data1:/mnt/data1,/path/to/data2:/mnt/data2`, where `path/to/*` are folders outside the singularity container, `/mnt/*` are those within the container. You may find out more about mounting [here](https://singularity-userdoc.readthedocs.io/en/latest/bind_paths_and_mounts.html).

In addition, note that for `--relative-root`, we provide the directory that's within the singularity container. Other argument paths should be relative to `--relative-root` **within** the container instead of not outside. A tip on this: imagine you're inside the container and in the directory of `--relative-root`, where are those files relative to here?

When the above command is running, you will see a moving progress bar. When it finishes, it looks like this:

```console
Extracting .mif data...
100%|█████████████████████████████████████████| 100/100 [00:03<00:00, 30.33it/s]
```

Now you got the converted HDF5 file `demo_FDC_n100.h5` in folder `/myProject/data`.

### Step 3. Run ModelArray
#### Step 3.1. Prepare an R script to run
We recommend to first prepare an R script of running ModelArray. To prepare it, you may try out the commands of `ModelArray` either on your local computer in RStudio, or in the interactive R console that is launched by `singularity run --cleanenv -B ${dir_data}:${dir_mounted_data} ${fn_singularity} R`. As noted, the best practice is still to mount the directory.

<!---
Note: seems like even without mounting but as long as running R, i.e., `singularity run --cleanenv modelarray_confixel_latest.sif R` can still see the folder outside the singularity, e.g., `/cbica/projects/xxx/xxx`. It might be only available when running R
--->

An example R script is as below. Please refer to webpage `vignette("walkthrough")` for detailed explanation.

```{r example R script, eval=FALSE}
rm(list=ls())
library(ModelArray)

# =======================================
# Define input filenames
# =======================================
# the mounted data directory in singularity container:
dir_mounted_data <- "/mnt/myProject/data"
# filename of example fixel-wise data (.h5 file):
h5_path <- file.path(dir_mounted_data, "demo_FDC_n100.h5")
# filename of example fixel-wise data (.h5 file):
csv_path <- file.path(dir_mounted_data, "cohort_FDC_n100.csv")

# =======================================
# Get ready
# =======================================
# create a ModelArray-class object:
modelarray <- ModelArray(h5_path, scalar_types = c("FDC"))
# load the CSV file:
phenotypes <- read.csv(csv_path)

# =======================================
# Run statistical analysis
# =======================================
formula.lm <- FDC ~ Age + sex + dti64MeanRelRMS
# run linear model fitting with ModelArray.lm()
mylm <- ModelArray.lm(formula.lm, modelarray, phenotypes, "FDC",
                      # element.subset = 1:100,
                      n_cores = 4)

# Notes: Make sure you also request >=4 CPU cores on the cluster when running the job.
# Notes: Above is a full run of all fixels which will take some time;
#        if you want to quickly test out first, add `element.subset = 1:100` in `ModelArray.lm()`.

# =======================================
# Write the results
# =======================================
writeResults(h5_path, df.output = mylm, analysis_name = "results_lm")

# =======================================
# Check the results (optional)
# =======================================
# create a new ModelArray-class object:
modelarray_new <- ModelArray(filepath = h5_path, scalar_types = "FDC",
                             analysis_names = c("results_lm"))
modelarray_new
```

Let's name this R script as `run_ModelArray.R`, and save it to `/myProject/code` folder, so the current folder structure is like:
```{.console}
/myProject
├── code
│   ├── run_ModelArray.R
│   └── ...
└── data
    ├── cohort_FDC_n100.csv
    ├── demo_FDC_n100.h5
    ├── FDC
    │   ├── directions.mifs
    │   ├── index.mif
    │   ├── sub-010b693.mif
    │   ├── sub-0133f31.mif
    │   ├── sub-063fd82.mif
    │   ├── ...
    └── ...
```

#### Run singularity image and call the R script

Below are the example commands to run the singularity image and call above R script. Let's name it as `call_ModelArray.sh` and also save it to folder `code`, the same folder as the R script.

```{.console}
#!/bin/bash

# This is to call `run_ModelArray.R`.
# Assume this script is in the same folder as the R script.

# +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
filename_Rscript="run_ModelArray.R"

dir_project="/myProject"
dir_mounted_project="/mnt/myProject"
dir_code="${dir_project}/code"
# +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

cd $dir_code
date

singularity run --cleanenv -B ${dir_project}:${dir_mounted_project} \
    ${fn_singularity} \
    Rscript ${dir_mounted_project}/code/${filename_Rscript} \
    > printed_message.txt 2>&1   # this is path on cluster, as it's outside the singularity container

date
```

Here, we directly mount the `/myProject` directory as `/mnt/myProject`. This is to make sure that data and scripts are all mounted.

`> printed_message.txt 2>&1` is to save the messages that are printed in the terminal console into a text file, so that you can still view it afterwards (or during the job is running). Only for the path of this file you should use path on cluster; for other paths, you should use the path within the container.

You may run above bash file in an interactive terminal, however, this is probably not the best practice. To avoid the connection disruption that stops the command from running, we suggest submitting a job to run this bash file on the cluster.

Different clusters have different systems, and the job submission commands are different, so please consult the manual of the cluster you're using for job submission. Specifically for SGE, you may submit the job by `qsub -l h_vmem=${h_vmem} -pe threaded ${num_cores} call_ModelArray.sh`. Here, `${num_cores}` should be consistent with `n_cores` in `ModelArray.lm()`. For `h_vmem`, the more `n_cores` you request, or the more complicated the statistical model it is (see `formula`), the more `h_vmem` it needs. We suggest to request a bit more than it actually needs so that your job won't get killed. For example, with `n_cores=4`, formula as above (`FDC ~ Age + sex + dti64MeanRelRMS`), and running `ModelArray.lm()`, you might request several GB (e.g., 10GB) just to be safe.



### Step 4. Convert the statistical results into mif file format using ConFixel

We now use `ConFixel` to convert the results into a list of mif files:

```{.console}
cd ${dir_data}

singularity run --cleanenv -B ${dir_data}:${dir_mounted_data} \
    ${fn_singularity} \
    fixelstats_write \
    --index-file FDC/index.mif \
    --directions-file FDC/directions.mif \
    --cohort-file cohort_FDC_n100.csv \
    --relative-root ${dir_mounted_data} \
    --analysis-name results_lm \
    --input-hdf5 demo_FDC_n100.h5 \
    --output-dir results_lm
```

After it's done, you'll see a new folder called `results_lm` with all the converted mif files. You may view them in `MRView`.


## More Information?
For more, please refer to:

* Detailed example walkthrough of `ModelArray` and `ConFixel`: see webpage `vignette("walkthrough")`
* Possible errors and how to debug: see webpage `vignette("debugging")`

